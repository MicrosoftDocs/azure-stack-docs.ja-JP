---
title: Azure Stack Hub でデータ センターを拡張する方法 | Microsoft Docs
description: Azure Stack でデータ センターを拡張する方法について説明します。
services: azure-stack
author: mattbriggs
ms.service: azure-stack
ms.topic: how-to
ms.date: 11/07/2019
ms.author: mabrigg
ms.reviewer: sijuman
ms.lastreviewed: 11/07/2019
ms.openlocfilehash: 92e82f549cddf51b1cbd6764cc122acc3ca8fdfc
ms.sourcegitcommit: ed44d477b9fd11573d1e0d1ed3a3c0ef4512df53
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 11/08/2019
ms.locfileid: "73846013"
---
# <a name="how-to-extend-the-data-center-on--azure-stack-hub"></a>Azure Stack Hub でデータ センターを拡張する方法

*適用対象:Azure Stack Hub 統合システムと Azure Stack Hub Development Kit*

この記事では、Azure Stack を既存のネットワーク環境に統合する方法を決めるのに役立つ Azure Stack Hub ストレージ インフラストラクチャの情報を提供します。 データ センターの拡張について概要を説明した後、2 つの異なるシナリオを紹介します。 Windows ファイル ストレージ サーバーに接続できます。 Windows iSCSI サーバーに接続することもできます。

## <a name="overview-of-extending-storage-to-azure-stack-hub"></a>Azure Stack Hub へのストレージの拡張の概要

データをパブリック クラウドに格納しても十分ではないシナリオがあります。 たとえば、遅延に敏感な、コンピューティング集中型の仮想化されたデータベース ワークロードがあり、パブリック クラウドへのラウンド トリップ時間がデータベース ワークロードのパフォーマンスに影響を与える場合があります。 たとえば、ファイル サーバー、NAS、または iSCSI のストレージ アレイに保持されているオンプレミスのデータがあるとします。それには、オンプレミスのワークロードがアクセスする必要があり、また、規制やコンプライアンスの目標を達成するために、それはオンプレミスに配置されている必要があります。  これらは、データをオンプレミスに常駐させることが、多くの組織にとって重要であることに変わりはないという 2 つのシナリオに過ぎません。

では、なぜ Azure Stack 上のストレージ アカウントで、または Azure Stack システムで実行されている仮想化されたファイル サーバー内でそのデータをホストしないのでしょうか。 Azure とは異なり、Azure Stack のストレージは有限です。 使用量として使用可能な容量は、所有するノードの数に加え、購入することを選択したノードごとの容量によってすべて決まります。 また Azure Stack はハイパーコンバージド ソリューションであるため、使用量のニーズに合わせてストレージ容量を拡大することが必要になった場合は、ノードの追加によってコンピューティングの占有領域を増加することも必要になります。  このコストは、特に追加容量のニーズが、Azure Stack システムの外では低料金で追加できるコールド アーカイブ ストレージの場合、莫大なものになる可能性があります。

このようなことから以下のシナリオをご検討ください。 どうすれば、Azure Stack のシステム (Azure Stack 上で実行されている仮想化されたワークロード) を、ネットワーク経由でアクセス可能な Azure Stack 外部のストレージ システムに、簡単かつ効率的に接続できるでしょうか。

## <a name="design-for-extending-storage"></a>ストレージを拡張するための設計

この図は、ワークロードを実行している単一の仮想マシンを、データの読み取り/書き込みなどの目的で、外部 (VM や Azure Stack 自体の) ストレージに接続して利用するシナリオを示しています。この記事では、ファイルの簡単な取得に焦点を当てますが、データベース ファイルのリモート ストレージなど、より複雑なシナリオに合わせてこの例を拡張することもできます。

![Azure Stack 拡張ストレージ](./media/azure-stack-network-howto-extend-datacenter/image1.png)

この図では、Azure Stack システム上の VM が複数の NIC を使用してデプロイされていることがわかります。 冗長性だけでなく、ストレージのベスト プラクティスとしても、ターゲットと宛先の間に複数のパスを用意することが重要です。 状況が複雑になるのは、Azure と同様に、Azure Stack の VM にパブリック IP とプライベート IP の両方がある場合です。 外部ストレージから VM に到達する必要がある場合は、パブリック IP を使用する必要があります。これは、プライベート IP は主に Azure Stack システム内、vNet およびサブネット内で使用されるためです。 外部ストレージは、サイト間 VPN を経由して vNet 自体に接続しない限り、VM のプライベート IP 空間と通信できません。 そのため、この例では、パブリック IP 空間を介した通信に注目します。 図のパブリック IP 空間で注目する点は、2 つの異なるパブリック IP プール サブネットがあることです。 既定で、パブリック IP アドレスの目的では Azure Stack には 1 つのプールのみが必要ですが、冗長ルーティングのためには、2 つ目のプールを追加することも考えられます。 ただし、1 つの特定のプールから IP アドレスを選択することはできないため、場合によっては複数の仮想ネットワーク カードにまたがる同じプールのパブリック IP を持つ VM を使用します。

この例では、境界デバイスと外部ストレージ間のルーティングが処理され、トラフィックがネットワークを適切に通過できると想定できます。 この例では、バックボーンが 1 GbE、10 GbE、25 GbE、またはそれより高速かどうかは関係ありませんが、統合を計画する際は、この外部ストレージにアクセスするアプリケーションのパフォーマンス ニーズに対処することを考慮することが重要です。

## <a name="connect-to-a-windows-server-file-server-storage"></a>Windows Server ファイル サーバー ストレージに接続する

このシナリオでは、Azure Stack に Windows Server 2019 仮想マシンをデプロイして構成し、外部ファイル サーバーに接続できるように準備します。これにより、Windows Server 2019 も実行できます。 必要に応じて、SMB マルチチャネルなどの主要な機能を設定して、VM と外部ストレージ間のパフォーマンスと接続を最適化します。

### <a name="deploy-the-windows-server-2019-vm-on-azure-stack"></a>Windows Server 2019 VM を Azure Stack にデプロイする

1.  **Azure Stack 管理者ポータル**から、このシステムが正しく登録され、マーケットプレースに接続されていると仮定して、 **[Marketplace Management]\(マーケットプレースの管理\)** を選択します。次に、WindowsServer 2019 イメージをまだ持っていないと仮定して、 **[Add from Azure]\(Azure から追加\)** を選択し、**Windows Server 2019** を検索し、**Windows Server 2019 Datacenter** イメージを追加します。

    ![](./media/azure-stack-network-howto-extend-datacenter/image2.png)

    Windows Server 2019 イメージのダウンロードには時間がかかる場合があります。

2.  Azure Stack 環境に Windows Server 2019 イメージを用意できたら、Azure Stack ユーザー ポータル**にサインインします。

3.  Azure Stack ユーザー ポータルにログインしたら、[オファーのサブスクリプション](https://docs.microsoft.com/azure-stack/operator/azure-stack-subscribe-plan-provision-vm?view=azs-1908)があることを確認します。これを使用して、IaaS リソース (コンピューティング、ストレージ、ネットワーク) をプロビジョニングできます。

4.  サブスクリプションを用意できたら、Azure Stack ユーザー ポータルの**ダッシュボード**に戻り、 **[リソースの作成]** を選択し、 **[Compute]** を選択してから、**Windows Server 2019 Datacenter ギャラリー項目**を選択します。

5.  **[基本]** ブレードで、次の操作を行います。

    a.  **Name**:VM001

    b.  **ユーザー名**: localadmin

    c.  **[パスワード]** 、 **[パスワードの確認]** : \<ご自分が選択したパスワード>

    d.  **サブスクリプション**: \<コンピューティング/ストレージ/ネットワーク リソースについてご自分が選択したサブスクリプション>

    e. **[リソース グループ]** :新規作成: storagetesting

    f.  **[OK]** を選択します。

6.  **[サイズの選択]** ブレードで **Standard_F8s_v2** を選択します。

7.  **[設定]** ブレードで **[仮想ネットワーク]** を選択し、 **[仮想ネットワークの作成]** ブレードでアドレス空間を **10.10.10.0/23** に調整し、[サブネット アドレス範囲] を **10.10.10.0/24** に更新し、 **[OK]** を選択します。

8.  **[パブリック IP アドレス]** を選択し、 **[パブリック IP アドレスの作成]** ブレードで **[静的]** を選択します。

9.  **[パブリック受信ポートを選択]** で、 **[RDP (3389)]** を選択します。

10. 他の既定値をそのまま使用し、 **[OK]** を選択します。
    
    ![](./media/azure-stack-network-howto-extend-datacenter/image3.png)

11. 概要を読み、検証を待ってから **[OK]** を選択し、デプロイを開始します。 デプロイは約 10 分で完了します。

12. デプロイが完了したら、 **[リソース]** で 仮想マシン名 **VM001** を選択し、 *[概要]* ブレードにアクセスします。
    
    ![](./media/azure-stack-network-howto-extend-datacenter/image4.png)

13. [DNS 名] の下で **[構成]** を選択し、DNS 名前ラベル「**vm001」を指定し、 **[保存]** を選択して、階層リンクで **VM001** を選択して、 *[概要]* ブレードに戻ります。

14. [概要] ブレードの右側にある仮想ネットワーク/サブネットのテキストで **storagetesting-vnet/default** を選択します。

15. storagetesting-vnet ブレード内で **[サブネット]** 、 **[+サブネット]** の順に選択し、次の情報を入力します。 

    a.  **名前**: subnet2

    b.  **アドレス範囲 (CIDR ブロック)** :10.10.11.0/24

    c. **ネットワーク セキュリティ グループ**:なし

    d.  **[ルート テーブル]** :なし

    e. **[OK]** を選択します。

16. 保存されたら、階層リンクの **[VM001]** を選択して概要ブレードに戻ります。

17. **[ネットワーク]** を選択します。

18. **[ネットワーク インターフェイスの接続]** を選択し、 **[ネットワーク インターフェイスの作成]** を選択します。

19. **[ネットワーク インターフェイスの作成]** ブレードで次のようにします。

    a.  **名前**: vm001nic2

    b.  **サブネット**:サブネットが 10.10.11.0/24 であることを確認します

    c. **[ネットワーク セキュリティ グループ]** : VM001-nsg

    d.  **リソース グループ**: storagetesting

20. 正常に作成されたら、階層リンクの **[VM001]** を選択し、 **[停止]** を選択して VM をシャットダウンします。

21. VM が停止 (割り当て解除) されたら、 **[ネットワーク]** を選択し、 **[ネットワーク インターフェイスの接続]** を選択し、 **[vm001nic2]** を選択して **[OK]** を選択します。 しばらくしてから、VM に NIC を追加します。

22. **[ネットワーク]** ブレードで、 **[vm001nic2]** タブを選択し、 **[ネットワーク インターフェイス: vm001nic2]** を選択します。

23. vm001nic インターフェイス ブレードで **[IP 構成]** を選択し、ブレードの中央にある **[ipconfig1]** を選択します。

24. ipconfig1 の設定ブレードで、[パブリック IP アドレス] に **[有効]** を選択し、 **[必要な設定の構成]** 、 **[新規作成]** の順に選択し、名前に「vm001nic2pip」と入力し、 **[静的]** を選択し、 **[OK]** 、 **[保存]** の順に選択します。

25. 正常に保存されたら、VM001 の概要ブレードに戻り、 **[開始]** を選択して、構成された Windows Server 2019 VM を開始します。

### <a name="configure-the-windows-server-2019-file-server-storage"></a>Windows Server 2019 ファイル サーバー ストレージを構成する

この最初の例では、Windows Server 2019 ファイル サーバーが Hyper-V で実行されている仮想マシンである構成を検証します。 この仮想マシンは、8 つの仮想プロセッサ、1 つの VHDX ファイル、そして最も重要な 2 つの仮想ネットワーク アダプターで構成されます。 理想的なシナリオでは、これらのネットワーク アダプターはルーティング可能なサブネットが異なりますが、このテストでは、同じサブネット上にネットワーク アダプターがあります。

![](./media/azure-stack-network-howto-extend-datacenter/image5.png)

ファイル サーバーの場合、Windows Server 2016 または 2019、物理または仮想、Hyper-V、VMware、または選択した代替プラットフォームで実行できます。 ここで重要な焦点は、Azure Stack システムとの相互接続ですが、ソースと宛先の間に複数のパスを用意することが推奨されます。これは、追加の冗長性を実現し、SMB マルチチャネルなど、より高度な機能を使用してパフォーマンスを向上させるためです。

ファイル共有の構成に進む前に、最新の累積的な更新プログラムと修正プログラムでファイル サーバーを更新して再起動します。

更新して再起動すると、このサーバーをファイル サーバーとして構成できるようになります。

1) ファイル サーバー マシン上で、**CMD** から **ipconfig /all** を実行し、ファイル サーバーで使用されている **DNS サーバー**をメモしておきます。

2)  **[サーバー マネージャー]** を開き、 **[管理]** 、 **[役割と機能の追加]** の順に選択します。

3)  **[次へ]** を選択し、 **[役割ベースまたは機能ベースのインストール]** を選択し、 **[サーバーの役割の選択]** ページまで選択を進めます。

4)  **[ファイル サービスと記憶域サービス]** を展開し、 **[ファイル サービスおよび iSCSI サービス]** を展開し、 **[ファイル サーバー]** を選択します。 完了したら、 **[サーバー マネージャー]** を閉じます。

5)  **[サーバー マネージャー]** を再び開き、 **[ファイル サービスと記憶域サービス]** を選択します。

6)  **[共有]** を選択します。

7)  **[共有]** ボックスで、 **[ファイル共有を作成するには、新しい共有ウィザードを実行してください]** リンクを選択します。

8)  **[新しい共有ウィザード]** ボックスで、 **[SMB 共有 - 簡易]** を選択し、 **[次へ]** を選択します。ウィザードの手順を進めて、**C:\\\\ボリューム**を選択します。

9)  共有に **TestStorage** と名前を付け、、 **[次へ]** を選択します。

10) **新しい共有ウィザード**に戻り、 **[次へ]** 、 **[作成]** 、 **[閉じる]** の順に選択します。

これで、ファイル サーバー上にファイル共有が作成されました。

### <a name="testing-file-storage-performance-and-connectivity"></a>ファイル ストレージのパフォーマンスと接続性のテスト

通信を確認し、いくつかの基本的なテストを実行するには、**Azure Stack** システムの Azure Stack ユーザー ポータルにサインインし、**VM001** の **[概要]** ブレードに移動します。

1)  **[接続]** を選択して VM001 への RDP 接続を確立します。

2)  ホスト名を使用して通信するには、**Hosts** ファイルを編集します。ただし、運用環境では、名前が自動的に解決されるように DNS を最適に構成します。 IP アドレスを使用することもできます。 ただし、この例では、**Hosts** ファイルを編集します。

3)  **[管理者として実行]** を使用して**メモ帳**を開きます。

4)  メモ帳を開いたら、 **[ファイル]** 、 **[開く]** を選択し、c:\\Windows\System32\Drivers\etc\, を参照し、開いているダイアログ ボックスの右下で **[すべてのファイル]** を選択します。 **hosts** ファイルを選択し、 **[開く]** を選択します。

5)  hosts ファイルを編集し、ファイル サーバーの IP アドレスと DNS 名を追加します。

    ![](./media/azure-stack-network-howto-extend-datacenter/image6.png)

6)  ファイルを保存して、メモ帳を閉じます。

7)  **CMD** を開き、hosts ファイルに入力したファイル サーバーの名前を ping します。 これにより、ファイル サーバー上のいずれかのネットワーク アダプターの IP アドレスが返されるため、IP アドレスに ping して、他のアダプターとの通信を手動でテストします。

## <a name="connect-to-a-windows-server-iscsi-target-server"></a>Windows Server iSCSI ターゲット サーバーに接続する

このシナリオでは、Azure Stack 上で Windows Server 2019 の仮想マシンをデプロイして構成し、外部の iSCSI ターゲット サーバー (ここでも Windows Server 2019 が実行されます) に接続するように準備します。

> [!Note]  
> シナリオ 1 を既に完了している場合は、先に進んでマシンをカスタマイズします。

### <a name="deploy-the-windows-server-2019-vm-on-azure-stack"></a>Windows Server 2019 VM を Azure Stack にデプロイする

Azure Stack に Windows Server 2019 VM をまだデプロイしていない場合は、「[Windows Server 2019 VM を Azure Stack にデプロイする](#deploy-the-windows-server-2019-vm-on-azure-stack)」の手順に従ってください。 その後、Windows Server 2019 iSCSI ターゲットを構成できます。

### <a name="configure-the-windows-server-2019-iscsi-target"></a>Windows Server 2019 iSCSI ターゲットを構成する

この 2 つ目のシナリオでは、Windows Server 2019 iSCSI ターゲットが Hyper-V 上で実行されている仮想マシンである構成を検証します。 この仮想マシンは、8 つの仮想プロセッサ、1 つの VHDX ファイル、そして最も重要な 2 つの仮想ネットワーク アダプターで構成されます。 理想的なシナリオでは、これらのネットワーク アダプターはルーティング可能なサブネットが異なりますが、このテストでは、同じサブネット上にネットワーク アダプターがあります。

![](./media/azure-stack-network-howto-extend-datacenter/image5.png)

iSCSI ターゲットの場合、Windows Server 2016 または 2019、物理または仮想、Hyper-V、VMware、または選択した代替プラットフォームで実行できます。 ここで重要な焦点は、Azure Stack システムとの相互接続ですが、ソースと宛先の間に複数のパスを用意することが推奨されます。これは、追加の冗長性とスループットを実現するためです。

iSCSI ターゲット サーバーの構成に進む前に、最新の累積的な更新プログラムと修正プログラムでファイル サーバーを更新して再起動します。

更新して再起動すると、このサーバーを iSCSI ターゲット サーバーとして構成できるようになります。

1. **サーバー マネージャー** >  **[管理]**  >  **[役割と機能の追加]** の順に開きます。

2. 開いたら、 **[次へ]** を選択し、 **[役割ベースまたは機能ベースのインストール]** を選択し、 **[サーバーの役割の選択]** ページに到達するまで選択を進めます。

3. **[ファイル サービスと記憶域サービス]** を展開し、 **[ファイル サービスおよび iSCSI サービス]** を展開して **[iSCSI ターゲット サーバー]** を選択し、新しい機能を追加するプロンプトを受け入れ、完了まで進みます。

    ![](./media/azure-stack-network-howto-extend-datacenter/image8.png)
    
    完了したら、**サーバー マネージャー**を閉じます。

4. **エクスプローラー**を開いて `C:\\` に移動し、`iSCSI` という**新しいフォルダーを作成**します。

5. 左側のメニューから、 **[サーバー マネージャー]**  >  **[ファイル サービスと記憶域サービス]** をもう一度開きます。

6. **[iSCSI]** を選択し、 **[iSCSI 仮想ディスクを作成するには、新しい iSCSI 仮想ディスク ウィザードを開始してください]** を選択します。

7. **[iSCSI 仮想ディスクの場所を選択]** ページで **[カスタム パスを入力してください]** を選択し、`C:\\iSCSI` を参照します。 **[次へ]** を選択します。

8. iSCSI 仮想ディスクに `iSCSIdisk1` という名前を付け、必要に応じて説明を入力し、 **[次へ]** を選択します。

9. 仮想ディスクのサイズを `10GB` に設定し、 **[固定サイズ]** を選択し、 **[次へ]** を選択します。

    ![](./media/azure-stack-network-howto-extend-datacenter/image9.png)

10. これは新しいターゲットであるため、 **[New iSCSI target]\(新しい iSCSI ターゲット\)** を選択し、 **[次へ]** を選択します。

11. **[ターゲット名の指定]** ページで「**TARGET1**」と入力し、 **[次へ]** を選択します。

12. **[アクセス サーバーの指定]** ページで **[追加]** を選択します。 これにより、iSCSI ターゲットへの接続が承認される特定の**イニシエーター**を入力するためのダイアログが開きます。

13. **[イニシエーター ID の追加]** ウィンドウで **[選択した種類の値の入力]** を選択し、 **[種類]** で、IQN がドロップダウン メニューで選択されていることを確認します。 「`iqn.1991-05.com.microsoft:<computername>`」と入力します。ここで、`<computername>` は、**VM001** の**コンピューター名**です。 **[次へ]** を選択します。

    ![](./media/azure-stack-network-howto-extend-datacenter/image10.png)

14. **[認証を有効にする]** ページで、ボックスを空白のままにして、 **[次へ]** を選択します。

15. 選択内容を確認して **[作成]** を選択してから、閉じます。

    ![](./media/azure-stack-network-howto-extend-datacenter/image11.png)

サーバー マネージャーで作成した iSCSI 仮想ディスクが表示されます。

### <a name="configure-the-windows-server-2019-iscsi-initiator-and-mpio"></a>Windows Server 2019 iSCSI イニシエーターと MPIO を構成する

iSCSI イニシエーターを設定するには、**Azure Stack** システムの**ユーザー ポータル**にサインインし、**VM001** の **[概要]** ブレードに移動します。

1.  VM001 への RDP 接続を確立します。 接続したら、**サーバー マネージャー**を開きます。

2.  **[役割と機能の追加]** を選択し、 **[機能]** ページが表示されるまで、既定値を受け入れます。

3.  **[機能]** ページで **[マルチパス I/O]** を追加し、 **[次へ]** を選択します。

    ![](./media/azure-stack-network-howto-extend-datacenter/image12.png)

4.  **[必要に応じてターゲット サーバーを自動的に再起動する]** ボックスをオンにして **[インストール]** を選択し、 **[閉じる]** を選択します。 再起動が必要になる可能性が高いため、完了したら VM001 に再接続します。

5.  **サーバー マネージャー**に戻り、**MPIO のインストールが完了する**のを待って **[閉じる]** を選択してから、 **[ツール]** を選択し、 **[MPIO]** を選択します。

6.  **[マルチパスの検出]** タブを選択し、ボックス **[iSCSI デバイスのサポートを追加する]**  >  **[追加]** を選択し、 **[はい]** を選択して VM001 を**再起動**します。 **[OK]** を選択し、手動で再起動します。

    ![](./media/azure-stack-network-howto-extend-datacenter/image13.png)

1.  再起動したら、**VM001 への新しい RDP 接続**を確立します。

2.  接続したら、**サーバー マネージャー**を開き、 **[ツール]**  >  **[iSCSI イニシエーター]** の順に選択します。

3.  Microsoft iSCSI を開いたときに、既定で iSCSI サービスを実行できるようにするには、 **[はい]** を選択します。

    ![](./media/azure-stack-network-howto-extend-datacenter/image17.png)

4.  **[探索]** タブを選択します。

5.  **[ポータルの探索]** ボタンを選択します。 ここでは、2 つのターゲットを追加します。

6.  iSCSI ターゲット サーバーの最初の IP アドレスを入力し、 **[詳細]** を選択します。

    ![](./media/azure-stack-network-howto-extend-datacenter/image15.png)

7. **[詳細設定]** で次を選択します。

    - ローカル アダプター: Microsoft iSCSI イニシエーター

    - イニシエーター IP: 10.10.10.4

    - 設定されたら、 **[OK]** を選択します。

8.  **[ターゲット ポータルの探索]** で **[OK]** を選択します。

9.  以下で、プロセスを繰り返します。

    - IP アドレス:2 番目の iSCSI ターゲット IP アドレス

    - ローカル アダプター: Microsoft iSCSI イニシエーター

    - イニシエーター IP: 10.10.11.4

10. ターゲット ポータルは次のようになります。 **[アドレス]** 列には、独自の iSCSI ターゲット IP が指定されています。

    ![](./media/azure-stack-network-howto-extend-datacenter/image16.png)

11. **[ターゲット]** タブを選択し、iSCSI ターゲットを選択します。 **[接続]** を選択します。

12. **[ターゲットへの接続]** で **[複数パスを有効にする]** を選択し、 **[詳細]** を選択します。

    ![](./media/azure-stack-network-howto-extend-datacenter/image17.png)

13. **[ターゲットへの接続]** に対して、次の情報を入力します。

    - ローカル アダプター: Microsoft iSCSI イニシエーター

    - イニシエーター IP: 10.10.10.4

    - ターゲット ポータル IP: \<最初の iSCSI ターゲット IP / 3260>

    - **[OK]** を選択します。

    ![](./media/azure-stack-network-howto-extend-datacenter/image18.png)

1.  2 番目のイニシエーターとターゲットの組み合わせに対して、このプロセスを繰り返します。

    - ローカル アダプター: Microsoft iSCSI イニシエーター

    - イニシエーター IP: 10.10.11.4

    - ターゲット ポータル IP: \<2 番目の iSCSI ターゲット IP / 3260>

    ![](./media/azure-stack-network-howto-extend-datacenter/image19.png)

1.  **[ボリュームとデバイス]** タブを選択し、 **[自動構成]** を選択します。次のように MPIO ボリュームが提示されます。

    ![](./media/azure-stack-network-howto-extend-datacenter/image20.png)

2.  **[ターゲット]** タブに戻り、 **[デバイス]** を選択すると、前に作成した 1 つの iSCSI VHD への 2 つの接続が表示されます。

    ![](./media/azure-stack-network-howto-extend-datacenter/image20.png)

3.  **[MPIO]** ボタンを選択すると、負荷分散ポリシーとパスの詳細情報が表示されます。

    ![](./media/azure-stack-network-howto-extend-datacenter/image21.png)

4.  **[OK]** を 3 回選択してウィンドウと iSCSI イニシエーターを閉じます。

5.  ディスク管理 (diskmgmt.msc) を開くと、 **[ディスクの初期化]** ポップアップが表示されます。

    ![](./media/azure-stack-network-howto-extend-datacenter/image22.png)

6.  **[OK]** を選択して既定値を受け入れ、新しいディスクまでスクロールダウンし、右クリックして、 **[新しいシンプル ボリューム]** を選択します。

7.  ウィザードの指示に従って、既定値を受け入れます。 ボリューム ラベルを「**iSCSIdisk1**」に変更し、 **[完了]** を選択します。

    ![](./media/azure-stack-network-howto-extend-datacenter/image23.png)

8.  これにより、ドライブがフォーマットされ、ドライブ文字が表示されます。

9.  **エクスプローラー** >  **[PC]** を開くと、新しいドライブが VM001 に接続されているのを確認できます。

### <a name="test-external-storage-connectivity"></a>外部ストレージ接続をテストする

通信を確認して、基本的なファイル コピー テストを実行するには、**Azure Stack** システムの**ユーザー ポータル**にサインインし、**VM001** の **[概要]** ブレードに移動します。

1. **[接続]** を選択して **VM001** への RDP 接続を確立します。

2. **タスク マネージャー**を開き、 **[パフォーマンス]** タブを選択します。ウィンドウを RDP セッションの右側にスナップします。

3. 管理者として **Windows PowerShell ISE** を開き、RDP セッションの左側にスナップします。 ISE の右側で、 **[コマンド]** ペインを閉じ、 **[スクリプト]** ボタンを選択して、ISE ウィンドウの上部にある白いスクリプト ペインを展開します。

4. この VM には、iSCSI ターゲットへのファイル転送をテストするための大きなファイルとして使用する VHD を作成するためのネイティブ PowerShell モジュールがありません。 この場合は、DiskPart を実行して VHD ファイルを作成します。 ISE で、次を実行します。

    1. `Start-Process Diskpart`

    2. 新しいコマンド プロンプトが開きます。 次のコマンドを入力します。<br>`Create vdisk file="c:\\test.vhd" type=fixed maximum=5120`

    ![](./media/azure-stack-network-howto-extend-datacenter/image24.png)

    作成にはしばらく時間がかかります。 作成されたら、作成を検証するために、**エクスプローラー**を開き、C:\\ に移動します。新しい test.vhd があり、サイズが 5 GB であることを確認できます。

    ![](./media/azure-stack-network-howto-extend-datacenter/image25.png)

    コマンド プロンプトを閉じます。 ISE に戻り、ISE で次のコマンドを入力します。 F:\\ は、前に適用した iSCSI ターゲット ドライブ文字に置き換えます。

    1. `Copy-Item "C:\\test.vhd" -Destination "F:\\"`

    2. ISE 内の行を選択します。 キーボードで **F8** キーを押します。

    3. コマンドが実行されている間、2 つのネットワーク アダプターを監視し、VM001 の両方のネットワーク アダプター間でデータの転送が行われていることを確認します。 また、各ネットワーク アダプターで負荷が均等に共有されていることにも注意してください。

        ![](./media/azure-stack-network-howto-extend-datacenter/image26.png)

このシナリオは、Azure Stack で実行されているワークロードと外部ストレージ アレイ (この場合、Windows Server ベースの iSCSI ターゲット) との間の接続に焦点を当てるように設計されました。 これは、パフォーマンス テストとして使用するように設計されたものではなく、また別の iSCSI ベースのアプライアンスを使用している場合に実行する必要がある手順も反映していません。これは、Azure Stack にワークロードをデプロイする際や Azure Stack 環境の外のストレージ システムに接続する際のいくつかの主な考慮事項に焦点を当てています。

## <a name="next-steps"></a>次の手順

[Azure Stack ネットワークの違いと考慮事項](azure-stack-network-differences.md)  